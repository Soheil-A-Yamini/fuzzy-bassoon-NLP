{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de814afd-14da-4adc-9c53-8f826bccbcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff02c366-1e21-490f-a502-30c3d178426c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d040945b5ea4d1e96ade3ab8d34542f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 22:34:44 INFO: Downloaded file to C:\\Users\\Soheil\\stanza_resources\\resources.json\n",
      "2025-02-25 22:34:44 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-02-25 22:34:46 INFO: File exists: C:\\Users\\Soheil\\stanza_resources\\en\\default.zip\n",
      "2025-02-25 22:34:48 INFO: Finished downloading models and saved to C:\\Users\\Soheil\\stanza_resources\n",
      "2025-02-25 22:34:48 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef0d2e7d405460ea29a3a3819c87780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 22:34:48 INFO: Downloaded file to C:\\Users\\Soheil\\stanza_resources\\resources.json\n",
      "2025-02-25 22:34:48 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-02-25 22:34:49 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2025-02-25 22:34:49 INFO: Using device: cuda\n",
      "2025-02-25 22:34:49 INFO: Loading: tokenize\n",
      "2025-02-25 22:34:50 INFO: Loading: mwt\n",
      "2025-02-25 22:34:50 INFO: Loading: pos\n",
      "2025-02-25 22:34:52 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntokenize,pos → Enables tokenization & POS tagging (Part-of-Speech tagging).\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stanza.download(\"en\")  # Download model (only needed once)\n",
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize,pos\", use_gpu=True)  # Load model\n",
    "\n",
    "\"\"\"\n",
    "tokenize,pos → Enables tokenization & POS tagging (Part-of-Speech tagging).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8dcf905-0d2c-4b19-a8a0-b041d26b45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_sentences = [\n",
    "    [\"He is a skilled engineer.\", \"He works in AI and robotics.\"],\n",
    "    [\"She is a professional researcher.\", \"She specializes in NLP.\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d794314-b78b-4ece-82f7-c1194d9c4f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: He, POS: PRON\n",
      "Word: is, POS: AUX\n",
      "Word: a, POS: DET\n",
      "Word: skilled, POS: ADJ\n",
      "Word: engineer, POS: NOUN\n",
      "Word: ., POS: PUNCT\n"
     ]
    }
   ],
   "source": [
    "sentence = nested_sentences[0][0]  # \"He is a skilled engineer.\"\n",
    "doc = nlp(sentence)  # Process using Stanza\n",
    "\n",
    "# Check the processed output\n",
    "for sent in doc.sentences:\n",
    "    for word in sent.words:\n",
    "        print(f\"Word: {word.text}, POS: {word.upos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163e93b6-8710-43ee-86f6-4d868c8809d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skilled']\n"
     ]
    }
   ],
   "source": [
    "#            [expression for sublist in main-list for item in iterable(sublist) if statement]\n",
    "adjectives = [word.text for sent in doc.sentences for word in sent.words if word.upos == \"ADJ\"]\n",
    "print(adjectives)  # Expected output: ['skilled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f9aa9-0b6e-4ec5-a92c-7c10d0d706cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300a582f-b9bf-4cb9-9030-3e0f99c9e343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09560060-5dca-4c06-bb21-6d1965c9ff79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She is a professional researcher.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2 = nested_sentences [1][0]\n",
    "sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425ae86-34da-49be-b244-a06845440035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" What is word.text, doc.sentences, ets?\"\n",
    "\"\"\"These are attributes commonly used in Natural Language Processing (NLP) libraries, such as SpaCy or Stanza, \n",
    "to access the structure of a text document.\n",
    "\n",
    "doc.sentences: is a list of sentence objects that represents the sentences in a document.\n",
    "\n",
    "sent.words: is a list of word objects (tokens) in a sentence. Each word has attributes such as text, upos (Universal Part-of-Speech tag), and more.\n",
    "\n",
    "Attribute\tWhat It Represents\n",
    "doc.sentences\tList of sentence objects in the document\n",
    "sent.words\tList of word objects (tokens) in a sentence\n",
    "word.text\tThe actual word (e.g., \"big\")\n",
    "word.upos\tThe Part-of-Speech (POS) tag (e.g., \"ADJ\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93d81c-b750-4d6e-9688-4b0b8e4c7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "adejctive2 = [word.text for  word.sentec in ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af0082f7-cdf9-4b67-bcc7-b0c05a21a545",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\n",
       "   {\n",
       "     \"id\": 1,\n",
       "     \"text\": \"He\",\n",
       "     \"upos\": \"PRON\",\n",
       "     \"xpos\": \"PRP\",\n",
       "     \"feats\": \"Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs\",\n",
       "     \"start_char\": 0,\n",
       "     \"end_char\": 2\n",
       "   },\n",
       "   {\n",
       "     \"id\": 2,\n",
       "     \"text\": \"is\",\n",
       "     \"upos\": \"AUX\",\n",
       "     \"xpos\": \"VBZ\",\n",
       "     \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
       "     \"start_char\": 3,\n",
       "     \"end_char\": 5\n",
       "   },\n",
       "   {\n",
       "     \"id\": 3,\n",
       "     \"text\": \"a\",\n",
       "     \"upos\": \"DET\",\n",
       "     \"xpos\": \"DT\",\n",
       "     \"feats\": \"Definite=Ind|PronType=Art\",\n",
       "     \"start_char\": 6,\n",
       "     \"end_char\": 7\n",
       "   },\n",
       "   {\n",
       "     \"id\": 4,\n",
       "     \"text\": \"skilled\",\n",
       "     \"upos\": \"ADJ\",\n",
       "     \"xpos\": \"JJ\",\n",
       "     \"feats\": \"Degree=Pos\",\n",
       "     \"start_char\": 8,\n",
       "     \"end_char\": 15\n",
       "   },\n",
       "   {\n",
       "     \"id\": 5,\n",
       "     \"text\": \"engineer\",\n",
       "     \"upos\": \"NOUN\",\n",
       "     \"xpos\": \"NN\",\n",
       "     \"feats\": \"Number=Sing\",\n",
       "     \"start_char\": 16,\n",
       "     \"end_char\": 24,\n",
       "     \"misc\": \"SpaceAfter=No\"\n",
       "   },\n",
       "   {\n",
       "     \"id\": 6,\n",
       "     \"text\": \".\",\n",
       "     \"upos\": \"PUNCT\",\n",
       "     \"xpos\": \".\",\n",
       "     \"start_char\": 24,\n",
       "     \"end_char\": 25,\n",
       "     \"misc\": \"SpaceAfter=No\"\n",
       "   }\n",
       " ]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34c41cf1-0a1f-4b30-b11a-663f118d67a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['skilled'], []], [['professional'], []]]\n"
     ]
    }
   ],
   "source": [
    "adjectives_nested = []\n",
    "for bio in nested_sentences:\n",
    "    adjectives_per_bio = []\n",
    "    for sentence in bio:\n",
    "        doc = nlp(sentence)  \n",
    "        adjectives = [word.text for sent in doc.sentences for word in sent.words if word.upos == \"ADJ\"]\n",
    "        adjectives_per_bio.append(adjectives)\n",
    "    adjectives_nested.append(adjectives_per_bio)\n",
    "\n",
    "print(adjectives_nested)  # [['skilled'], []], [['professional'], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4809dc10-cb3d-406e-a32b-144cab388bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_adj(x):\n",
    "    \n",
    "    adjectives_nested = []\n",
    "    for bio in nested_sentences:\n",
    "        adjectives_per_bio = []\n",
    "        for sentence in bio:\n",
    "            doc = nlp(sentence)  \n",
    "            adjectives = [word.text for sent in doc.sentences for word in sent.words if word.upos == \"ADJ\"]\n",
    "            adjectives_per_bio.append(adjectives)\n",
    "        adjectives_nested.append(adjectives_per_bio)\n",
    "    return adjectives_nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeba2ab9-b07a-4989-92aa-b9622b4f77cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['skilled'], []], [['professional'], []]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads = extract_adj(nested_sentences)\n",
    "ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4a13fd1-bc61-42b4-9a8e-e3b53ce29de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = [\" \".join([word.text for sent in doc.sentences for word in sent.words if word.upos != \"ADJ\"]) for word in sent.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1492edb-9d16-4f2d-a228-dc4441cf8a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remo_extract_adj(sat_bio):\n",
    "    adjectives_nested = []  # Store extracted adjectives\n",
    "    processed_texts = []  # Store bios without adjectives\n",
    "\n",
    "    for bio in sat_bio:  # Iterate over each bio (list of sentences)\n",
    "        adjectives_per_bio = []\n",
    "        modified_sentences = []  # Store sentences without adjectives\n",
    "        \n",
    "        for sentence in bio:\n",
    "            doc = nlp(sentence)  # Process sentence with Stanza\n",
    "            \n",
    "            # Extract adjectives\n",
    "            adjectives = [word.text for sent in doc.sentences for word in sent.words if word.upos == \"ADJ\"]\n",
    "            adjectives_per_bio.append(adjectives)\n",
    "            \n",
    "            # Remove adjectives and reconstruct sentence\n",
    "            modified_sentence = \" \".join([word.text for sent in doc.sentences for word in sent.words if word.upos != \"ADJ\"])\n",
    "            modified_sentences.append(modified_sentence)  # Add modified sentence\n",
    "\n",
    "        adjectives_nested.append(adjectives_per_bio)  # Keep nested structure\n",
    "        processed_texts.append(modified_sentences)  # Keep sentences grouped per bio\n",
    "\n",
    "    return adjectives_nested, processed_texts\n",
    "\n",
    "# Example input: Nested list of sentences\n",
    "# sat_bio = [\n",
    "#     [\"He is a skilled engineer.\", \"He works in AI and robotics.\"],\n",
    "#     [\"She is a professional researcher.\", \"She specializes in NLP.\"]\n",
    "# ]\n",
    "\n",
    "# Run the function\n",
    "# adjectives, modified_bios = remo_extract_adj(sat_bio)\n",
    "\n",
    "# # Print Results\n",
    "# print(\"Extracted Adjectives:\\n\", adjectives)\n",
    "# print(\"\\nModified Bios:\\n\", modified_bios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
